= リモートキャッシュ
:experimental:

=== Hot Rod クライアント
Hot Rod は、Infinispan が高性能なクライアント・サーバー間インタラクションのために提供するバイナリ TCP プロトコルであり、以下の機能を持ちます。:

* *ロードバランシング*: Hot Rod クライアントは、信頼性を向上させるために、様々な戦略を使って Infinispan クラスタ間でリクエストを送信できます。
* *フェイルオーバー*: Hot Rod クライアントは、Infinispan クラスタのトポロジーの変更を監視し、利用可能なノードに自動的に切り替えることができます。
* *効率的なデータ配置*: Hot Rod クライアントは key オーナーを見つけ、key オーナーを持つノードに直接リクエストを送信し、待ち時間を短縮することができます。


=== リモートキャッシュ
`RemoteCache` はその名の通り、リモートからアクセスできるキャッシュです。Data Grid サーバーはこのリモートキャッシュをホストし、クライアントはこのリモートキャッシュに接続します。
設計の観点から、より柔軟性があり、複数のキャッシュが存在するセントラル・デプロイメントを持つことができます。

Infinispan/Red Hat Data Grid の `RemoteCache` と `EmbeddedCache` の公開方法には違いがあります。
コレクションメソッド `keySet()`, `entrySet()`, `values()` はリモートキャッシュによってバックアップされます。
呼び出されたメソッドはすべて `RemoteCache` に送り返されます。
これは、様々なキーやエントリや値を遅延して取得することができ、ユーザが望まない場合にはそれらを一度にクライアントのメモリに保存する必要がないので便利です。

これらのコレクションは `Map` の仕様に準拠しており、`add()` と `addAll()` はサポートされていませんが、その他のメソッドはすべてサポートされています。
注意点としては、 `Iterator.remove()`、`Set.remove()`、`Collection.remove()` メソッドを使用する際には、サーバーとのラウンドトリップを複数回行う必要があるということです。
これらのメソッドやその他のメソッドの詳細については、 `RemoteCache` https://access.redhat.com/webassets/avalon/d/red-hat-data-grid/8.4/api/org/infinispan/client/hotrod/RemoteCache.html[Javadoc] を参照してください。


=== プロジェクト詳細
この例では、簡単なウェブ・アプリケーションを作成します。ウェブフォームからいくつかの入力を受け取り、エントリーをキャッシュに追加します。
しかし、今回は ProtoStream API を使って `RemoteCacheManager` を使用し、すべて Quarkus ベースのアプリケーションにて実装します。

早速始めましょう。まずはプロジェクトを見てみましょう。

{{ CHE_URL }}[CodeReady Workspaces^] に戻り、プロジェクト `dg8-quarkus-client-example` に移動します。これはテンプレートプロジェクトであり、この中にコードを記述します。
既にいくつかのファイルが用意されています。これらのファイルが何であり、何をしているのかを見てみましょう。


=== Maven 依存関係
プロジェクト内の `pom.xml` を開きます。

以下の依存関係を使用してサービスを作成します。

[source, xml]
----
    <dependency>
      <groupId>io.quarkus</groupId>
      <artifactId>quarkus-resteasy</artifactId> <1>
    </dependency>
    <dependency>
      <groupId>io.quarkus</groupId>
      <artifactId>quarkus-resteasy-jsonb</artifactId> <2> 
    </dependency>
    <dependency>
      <groupId>io.quarkus</groupId>
      <artifactId>quarkus-infinispan-client</artifactId> <3>
    </dependency>
    <dependency>
----

<1> `quarkus-resteasy` : REST エンドポイント
<2> `quarkus-resteasy-jsonb` : REST エンドポイントのための JSON シリアライゼーション
<3> `quarkus-infinispan-client` : Data Grid の `RemoteCache` の使用の有効化


=== Protobuf
Protobuf またはプロトコルバッファは、構造化データをシリアライズする方法です。
プロトコルバッファは、構造化データをシリアライズするための柔軟で効率的、かつ自動化されたメカニズムです。
様々なデータストリームに、様々な言語を使って、簡単にデータを書き込んだり読み込んだりすることができます。
Protobuf は構造化データがすべてなので、最初に行うことは構造を定義することです。
これは、`.proto` ファイルで Protobuf メッセージタイプを宣言することで実現できます。

この例では `game.proto`ファイルは次のようになっています。:

[source, protobuf, role="copypaste"]
----
package quickstart; <1> 

message Game { <2>
    required string name = 2; <3>
    required string description = 3; <4>
}
----

<1> メッセージのパッケージを定義します。
<2> メッセージの名前を定義します。メッセージはエンティティに似ています。
<3> メッセージが `name` という文字列であり、必須であることを指定します。
<4> メッセージは `description` という文字列であり、必須であることを指定します。

上記の内容を次のファイルに保存します。: src/main/resources/META-INF/game.proto`


=== マーシャラー
前のセクションで説明したように、Protobuf フォーマットの基本的な概念は、`.proto` スキーマでメッセージを定義し、エンティティの表現方法を決定することです。
しかし、Java アプリケーションにおいて Protobuf フォーマットを利用してデータを送信/保存するには、Javaオブジェクトをエンコードする必要があります。
これは、ProtoStream ライブラリと設定された Marshaller 実装によって処理され、POJO (plain old Java objects) を Protobuf 形式に変換します。

リソースの生成は ProtoStream を利用する最も簡単でパフォーマンスの高い方法ですが、この方法が常に実行できるとは限りません。
例えば、Java オブジェクト・クラスを変更して必要なアノテーションを追加できない場合などです。
このような使用例では、手動で `.proto` スキーマを定義して、手動マーシャラー実装を作成することができます。
マーシャラーを定義してみましょう。

`dg8-quarkus-client-example/src/main/java/org/acme/rest/json` フォルダにある `GameMarshaller` クラスを開きます。

以下のメソッドを `GameMarshaller` クラスに追加します。
以下のコードでは ProtoStream から *読み込む* 方法を指定しています。
必要であれば、ストリームに追加処理を加えることもできます。
単純な読み込みを行い、`Game` オブジェクトを返すことにします。
従って、ストリームが Cache から読み込まれるたびに、このメソッドが呼び出されることになります。

[source, java, role="copypaste"]
----
    @Override
    public Game readFrom(MessageMarshaller.ProtoStreamReader reader) throws IOException {
        String name = reader.readString("name");
        String description = reader.readString("description");
        return new Game(name, description);
    }
----

次に、*書き込み* メソッドも定義します。このメソッドは Game オブジェクトを受け取り、それをストリームに変換します。

[source, java, role="copypaste"]
----
    @Override
    public void writeTo(MessageMarshaller.ProtoStreamWriter writer, Game game) throws IOException {
        writer.writeString("name", game.getName());
        writer.writeString("description", game.getDescription());
    }
----

Stream データを扱うクラスを指定しましょう。

[source, java, role="copypaste"]
----
    @Override
    public Class<? extends Game> getJavaClass() {
        return Game.class;
    }
----

そして最後に、シリアライゼーションプロセスに、どの Proto タイプに対してこの処理を行うのか、すなわち packagename.Class を知らせます。:

[source, java, role="copypaste"]
----
    @Override
    public String getTypeName() {
        return "quickstart.Game";
    }
----

これでマーシャラーの設定ができました。


=== RemoteCache の設定
続いて RemoteCache の設定を作成しましょう。

`Init.java` を開いて、以下のメンバ変数を追加します。

[source, java, role="copypaste"]
----
    public static final String GAME_CACHE = "games"; <1>

    @Inject
    RemoteCacheManager cacheManager; <2> 

    private static final String CACHE_CONFIG = "<distributed-cache name=\"%s\">" <3>
          + " <encoding media-type=\"application/x-protostream\"/>" <4>
          + "</distributed-cache>";
----

<1> 初めにクラスレベルの変数にキャッシュの名前を指定します。
<2> `cacheManager` をインジェクトします。`CacheManager` は重いオブジェクトであり、起動時のみにロードします。
<3> コード内でキャッシュを設定するだけでなく、XML を使ってキャッシュを設定することもできます。`META-INF`ディレクトリにあるファイルから読み込むこともできますが、短いデモの場合はこの方法でも問題ありません。
<4> キャッシュのエンコーディングは、Protobuf でエンコードされたデータをキャッシュに格納し、最高の相互運用性とクエリサポートを得るために Protostream を使用しています。

[source, java, role="copypaste"]
----
    void onStart(@Observes @Priority(value = 1) StartupEvent ev) {
        String xml = String.format(CACHE_CONFIG, "games"); <1>
        cacheManager.administration().getOrCreateCache(GAME_CACHE, new XMLStringConfiguration(xml)); <2>
    }
----

`onStart()` メソッドは以前の演習で使ったので覚えているかもしれません。ここでも同じことをしています。
<1> `String` で定義した XML を Red Hat Data Grid サーバに渡して解析してもらい、`games` という新しいキャッシュを作成します。
<2> 次に `cacheManager` からキャッシュを取得するか、キャッシュが存在しない場合は新規作成するように依頼します。

これで `RemoteCacheManager` が設定されたはずですので、あとは REST リソースからこれを使うだけです。


=== REST エンドポイント

Open up the `GameResource.java` class. This class uses JAX-RS to define REST resources for our application.

In the following code, we inject our `RemoteCache` and we specify which remote cache we want by passing the variable `GAME_CACHE` to it, which we have initialized previously in our `Init` class.

Add this code to the `GameResource.java`

[source, java, role="copypaste"]
----
    @Inject
    @Remote(GAME_CACHE)
    RemoteCache<String, Game> gameStore;
----


The following are two simple GET and POST method implementations:

[source, java, role="copypaste"]
----
    @GET
    public Set<Game> list() {
        return new HashSet<>(gameStore.values());
    }

    @POST
    public Set<String> add(Game game) {
        gameStore.putAsync(game.getName(), game);
        return gameStore.keySet();
    }
----

<1> The `list` method is simply returning the games to the front-end.
<2> The `add` method is using the Async api of Infinispan/Red Hat Data Grid to add the entry into the cache.

Perfect. We are all set to deploy our application to Openshift and see how the `RemoteCache` will work.


=== Openshift へのデプロイとスケーリング

Let's prepare to deploy the application to Openshift

For this open up the `application.properties file` located in `src/main/resources/application.properties`

[source, properties, role="copypaste"]
----
%prod.quarkus.infinispan-client.server-list=datagrid-service:11222 <1>

# Auth. Set use-auth to false to connect to a non-authenticated Data Grid
%prod.quarkus.infinispan-client.use-auth=true<2>
%prod.quarkus.infinispan-client.auth-username=developer<3>
%prod.quarkus.infinispan-client.auth-password=bvTxphbrUvmkorxu<4>

# SSL configuration. Remove these properties if you disable SSL
%prod.quarkus.infinispan-client.trust-store=/var/run/secrets/kubernetes.io/serviceaccount/service-ca.crt<5>
%prod.quarkus.infinispan-client.trust-store-type=pem<6>


quarkus.http.cors=true

# Openshift extension settings.
quarkus.openshift.expose=true 

# if you dont set this and dont have a valid cert the deployment wont happen

quarkus.kubernetes-client.trust-certs=true
quarkus.container-image.build=true
quarkus.kubernetes.deploy=true
quarkus.infinispan-client.devservices.enabled=false

----

<1> Sets the Infinispan hostname/port to connect to. Each one is separated by a semicolon (eg. host1:11222;host2:11222).
<2> boolean for denoting that the authentication is on.
<3> Sets the username used by authentication, in our case, it is `developer`, the default from the operator.
<4> Sets the password used by authentication, we do not have this yet. We will find it out from the secrets. 
<5> The trust store for our certificate.
<6> And finally the trust store type.

Let's go fill in that password field in the above properties file.

Run the following command on the terminal and the passwords will be shown. Copy the password belonging to the `developer` user and add it to the password field `quarkus.infinispan-client.auth-password=`. 

[source, shell, role="copypaste"]
----
oc get secret datagrid-service-generated-secret -o jsonpath="{.data.identities\.yaml}" | base64 --decode
----

Let's go ahead and deploy the application to OpenShift. 

[source, shell, role="copypaste"]
----
mvn clean package -DskipTests -f $CHE_PROJECTS_ROOT/dg8-workshop-labs/dg8-quarkus-client-example
----

Let's wait for this build to be successful! Usually one would need to run all the commands to build the app, build the container and then create the YAML files. The Quarkus Openshift extension does this via its maven plugin in a simple one line command as we did here.

Now navigate to the link:{{ CONSOLE_URL }}[OpenShift web console^] and switch to the topology view.

image::gameserviceocp.png[cdw, 700, align="center"]

Find the `dg8-quarkus-client-example` application and click on the route to navigate to the application.

image::gameserviceocproute.png[cdw, 700, align="center"]

The application opens up in a different tab and shows the following interface. It allows you to save key-value pairs using a web form. Then, it automatically shows you the content of the cache below.

image::gamerestservice.png[cdw, 700, align="center"]

Try playing around with the application and adding some games. You can also try to delete some application and Data Grid pods to see how it behaves. 


=== ニアキャッシュの有効化
Near caches are optional caches for Hot Rod Java client implementations that keep recently accessed data close to the user, providing faster access to data that is accessed frequently. This cache acts as a local Hot Rod client cache that is updated whenever a remote entry is retrieved via `get` or `getVersioned` operations.

In Red Hat Data Grid, near cache consistency is achieved by using remote events, which send notifications to clients when entries are modified or removed (refer to Remote Event Listeners). With near caching, the local cache remains consistent with the remote cache. Local entry is updated or invalidated whenever remote entry on the server is updated or removed. At the client level, near caching is configurable as either of the following:

- *DISABLED* - the default mode, indicating that near caching is not enabled.
- *INVALIDATED* - enables near caching, keeping it in sync with the remote cache via invalidation messages.

image::nearcache.png[Near Caching, 700]

==== When should I use it? 
Near caching can improve the performance of an application when most of the accesses to a given cache are read-only and the accessed dataset is relatively small. When an application is doing lots of writes to a cache, invalidations, evictions, and updates to the near cache need to happen. In such a scenario the benefits a near cache provides won't necessarily be beneficial.

For Quarkus, near caching is disabled by default You can enable it by setting the profile config property `quarkus.infinispan-client.near-cache-max-entries` to a value greater than `0`. You can also configure a regular expression so that only a subset of caches have near caching applied through the `quarkus.infinispan-client.near-cache-name-pattern` property.


Add the following properties to our `application.properties` to enable near caching.

[source, properties, role="copypaste"]
----
quarkus.infinispan-client.cache.games.near-cache-mode=INVALIDATED 
quarkus.infinispan-client.cache.games.near-cache-max-entries=40 
----

WARNING: If during compilation or execution time you see a WARN like `Unrecognized configuration key "quarkus.infinispan-client.cache.games.near-cache-mode" was provided`, just go to your `pom.xml` and upgrade the `quarkus.platform.version` to `2.15.3.Final`.

Let's go ahead and redeploy the application to OpenShift. 

[source, shell, role="copypaste"]
----
mvn clean package -DskipTests -f $CHE_PROJECTS_ROOT/dg8-workshop-labs/dg8-quarkus-client-example
----

You should see a Build Successful message from this run as well. 

Notice that any entries that you might have added to the cache before this deployment are still there. That wasn't the case in the embedded cache, since we were not using any stores and every time the application started the cache was empty. In this case, since the cache is remote, you will still see the entries from last time. It is important to note that there are different ways you can configure and set up the cache. For more details visit the Documentation pages for Red Hat Data Grid.


=== Hibernate/JPA と Quarkus によるキャッシング

When using Hibernate ORM in Quarkus, you don't need to have a `persistence.xml` file for configuration. Using such a classic configuration file is an option, but unnecessary unless you have specific advanced needs. Let's see first how Hibernate ORM can be configured without a persistence.xml resource.

In Quarkus, you just need to:

- Add your configuration settings in `application.properties`
- Annotate your entities with `@Entity` and any other mapping annotation as usual

Other configuration needs have been automated: Quarkus will make some opinionated choices and educated guesses. 

[source, java, role="copypaste"]
----
package org.acme;

@Entity
@Cacheable
public class Country {
    // ...

    @OneToMany
    @Cache(usage = CacheConcurrencyStrategy.READ_ONLY)
    List<City> cities;

    // ...
}
----

In the above code, just using the `@Cacheable` annotation will make sure that Infinispan is used as the second-level cache for the entities. You also don't need to pick an implementation. A suitable implementation based on technologies Infinispan is included as a transitive dependency of the Hibernate ORM extension and automatically integrated during the build.


=== まとめ

. You learnt about `RemoteCache` and HotRod client.
. You learnt about Protostream and marshallers in Infinispan.
. You deployed your Quarkus app using `RemoteCache` to OpenShift.
. You learnt about near caching and its use case.
. Finally, we sum it up with JPA and Second Level Cache.

*Congratulations!!* you have completed this lab on RemoteCache. Let's move to the next lab and learn how we can use the new REST API in DataGrid to our advantage.
